<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Zaida Liendeborg, Emma Wallentinsson" />

<meta name="date" content="2016-10-14" />

<title>Ridgereg(), caret and dplyr</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Ridgereg(), caret and dplyr</h1>
<h4 class="author"><em>Zaida Liendeborg, Emma Wallentinsson</em></h4>
<h4 class="date"><em>2016-10-14</em></h4>



<p>This vignette tackles about the <strong>ridgereg()</strong> function and a short description of methods implemented in the function. The vignette shows example of predictive modelling for <strong>BostonHousing</strong> from <strong>mlbench</strong> package using both <strong>caret</strong> and the <strong>ridgereg()</strong> function.</p>
<div id="ridgereg-function" class="section level2">
<h2>Ridgereg() function</h2>
<p>The <strong>ridgereg()</strong> function fits a ridgre regression using the Ordinary Least Squares method. The function takes arguments <strong>formula, data and lambda.</strong> Formula should be the regression equation, it means to say both the response and the predictors. There should also be a dataset where the variables are taken from and a specified lambda value to be used to find the true parameters.</p>
<p>The function returns an list of a class <strong>ridgereg</strong> containing the regression equation used, the estimates of the beta coefficients and the fitted values.</p>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Loading required package: gridExtra</code></pre>
<pre><code>## Loading required package: maps</code></pre>
<pre><code>## Loading required package: maptools</code></pre>
<pre><code>## Loading required package: sp</code></pre>
<pre><code>## Checking rgeos availability: FALSE
##      Note: when rgeos is not available, polygon geometry     computations in maptools depend on gpclib,
##      which has a restricted licence. It is disabled by default;
##      to enable gpclib, type gpclibPermit()</code></pre>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## Loading required package: caret</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<p>There are three different methods implemented on the function and they will be discussed in the following sections:</p>
</div>
<div id="the-coef.ridgereg-method" class="section level2">
<h2>The coef.ridgereg method</h2>
<p>This <strong>coef()</strong> returns a name vector with the estimates of the beta coefficients from the fitted ridge regression. It only takes an object of a class ridgereg.</p>
<pre><code>##  (Intercept) Petal.Length  Petal.Width 
##    5.8433333    0.9563983   -0.2435735</code></pre>
</div>
<div id="the-print.ridgereg-method" class="section level2">
<h2>The print.ridgereg method</h2>
<p>By using <strong>print()</strong>, the response variable and the explanatory variables used by the ridge regression model prints out. It also gives the estimates of the beta coefficients. See example below:</p>
<pre><code>## $Call
## ridgereg(formula = Sepal.Length ~ Petal.Length + Petal.Width, 
##     data = iris, lambda = 0)
## 
## $Coefficients
##  (Intercept) Petal.Length  Petal.Width 
##    5.8433333    0.9563983   -0.2435735</code></pre>
</div>
<div id="the-predict.ridgereg-method" class="section level2">
<h2>The predict.ridgereg method</h2>
<p>The <strong>predict()</strong> method simply gives the predicted values of the fitted ridge regression model. It takes two arguments such as <strong>object and newdata</strong>. Object should be a ridgereg object and newdata is an optional data frame in which the prediction of new values would be based on. If there is no given new dataset, the predict function will simply return a numeric vector with the fitted values.</p>
<p>To show how predict works, let’s take iris data as an example. First let’s divide the data into two sets: <strong>training and test</strong> sets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(iris)
train&lt;-<span class="st"> </span>iris[<span class="dv">1</span>:<span class="dv">75</span>,]
test&lt;-<span class="st"> </span>iris[<span class="dv">76</span>:<span class="dv">150</span>,]

pred_ridgeobject&lt;-<span class="st"> </span><span class="kw">ridgereg</span>(<span class="dt">formula=</span> Sepal.Length ~<span class="st"> </span>Petal.Length +<span class="st"> </span>Petal.Width,
                       <span class="dt">data=</span>train, <span class="dt">lambda=</span><span class="dv">0</span>)

new_pred&lt;-<span class="st"> </span><span class="kw">predict</span>(pred_ridgeobject, <span class="dt">newdata=</span>test)

<span class="kw">head</span>(new_pred)</code></pre></div>
<pre><code>## [1] 5.891570 6.224989 6.288467 5.940514 5.279019 5.494673</code></pre>
</div>
<div id="predictive-model-for-the-bostonhousing-data-set" class="section level2">
<h2>Predictive model for the BostonHousing data set</h2>
</div>
<div id="section" class="section level2">
<h2>1</h2>
<p>A predictive model is created for the <em>BostonHousing</em> data set located in the <strong>mlbench</strong> package. First, the data is splitted in a training and test set using the <strong>caret</strong> package. The traning part is set to 75 % of the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mlbench)
<span class="kw">library</span>(leaps)
<span class="kw">data</span>(<span class="st">&quot;BostonHousing&quot;</span>) <span class="co">#load data</span>
<span class="kw">library</span>(caret)
inTrain &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> BostonHousing$medv,  <span class="dt">p =</span> .<span class="dv">75</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>) <span class="co">#data partitioning</span>

training &lt;-<span class="st"> </span>BostonHousing[ inTrain,] <span class="co">#training set </span>
testing &lt;-<span class="st"> </span>BostonHousing[-inTrain,] <span class="co"># test set </span></code></pre></div>
</div>
<div id="section-1" class="section level2">
<h2>2</h2>
<p>A linear regression model and a linear regression model with forward selection of covariates is fitted to the training set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmFit&lt;-<span class="kw">train</span>(medv~., <span class="dt">data =</span> training, <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>)<span class="co"># linear regression</span>
lmFitForw&lt;-<span class="kw">train</span>(medv~., <span class="dt">data=</span>training, <span class="dt">method=</span><span class="st">&quot;leapForward&quot;</span>)<span class="co"># forward selection</span></code></pre></div>
</div>
<div id="section-2" class="section level2">
<h2>3</h2>
<p>The evaluating of the performance of the models are being done on the linear regression model:</p>
<pre><code>##      RMSE  Rsquared 
## 4.6505586 0.7491115</code></pre>
<p>And on the fast forward regression model:</p>
<pre><code>##      RMSE  Rsquared 
## 5.0124752 0.7085427</code></pre>
<p>Which means that the linear regression model is better, due to the higher R square and lower RMSE.</p>
</div>
<div id="section-3" class="section level2">
<h2>4</h2>
<p>Now we fit a ridge regression model with our <strong>ridgereg</strong> function, different values of lambda.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lpRidgeReg &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">type =</span> <span class="st">&quot;Regression&quot;</span>,
                   <span class="dt">library =</span> <span class="st">&quot;multireg&quot;</span>,
                   <span class="dt">loop =</span> <span class="ot">NULL</span>) 

prm &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">parameter =</span> <span class="st">&quot;lambda&quot;</span>,
                  <span class="dt">class =</span> <span class="st">&quot;numeric&quot;</span>,
                  <span class="dt">label =</span> <span class="st">&quot;lambda&quot;</span>)


lpRidgeReg$parameters&lt;-prm

grid &lt;-<span class="st"> </span>function (x, y, <span class="dt">len =</span> <span class="ot">NULL</span>, <span class="dt">search =</span> <span class="st">&quot;grid&quot;</span>)
{
  if (search ==<span class="st"> &quot;grid&quot;</span>) {
    out &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">lambda =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">10</span>^<span class="kw">seq</span>(-<span class="dv">1</span>, -<span class="dv">4</span>, <span class="dt">length =</span> len -<span class="st"> </span><span class="dv">1</span>)))
  }
  else {
    out &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">lambda =</span> <span class="dv">10</span>^<span class="kw">runif</span>(len, <span class="dt">min =</span> -<span class="dv">5</span>, <span class="dv">1</span>))
  }
  out
}

lpRidgeReg$grid &lt;-<span class="st"> </span>grid

fitreg&lt;-function(x,y,lambda,param,lev,last,classProbs,...){
  
  if(<span class="kw">is.data.frame</span>(x)){
    dat&lt;-<span class="st"> </span>x
  }else{
    dat&lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(x)
  } 
  dat$medv&lt;-<span class="st"> </span>y

  frmla &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="kw">colnames</span>(dat)[<span class="kw">ncol</span>(dat)], 
                            <span class="kw">paste</span>(<span class="kw">colnames</span>(dat)[<span class="dv">1</span>:(<span class="kw">ncol</span>(dat)-<span class="dv">1</span>)],
                                  <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>, <span class="dt">collapse =</span> <span class="st">&quot; + &quot;</span>), <span class="dt">sep =</span> <span class="st">&quot; ~ &quot;</span>))
  
  model &lt;-<span class="st"> </span>multireg::<span class="kw">ridgereg</span>(<span class="dt">formula=</span> frmla, <span class="dt">data=</span>dat, <span class="dt">lambda=</span> param)
  <span class="kw">return</span>(model)
}

lpRidgeReg$fit&lt;-fitreg

pred &lt;-<span class="st"> </span>function(modelFit, newdata, <span class="dt">preProc =</span> <span class="ot">NULL</span>, <span class="dt">submodels =</span> <span class="ot">NULL</span>){
  <span class="kw">predict</span>(modelFit, newdata)
}

lpRidgeReg$predict &lt;-<span class="st"> </span>pred


lpRidgeReg$prob &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="ot">NULL</span>)


##

<span class="co">#trainridge &lt;- train(y=training$medv,x = training,method =lpRidgeReg)</span>
<span class="kw">train</span>(<span class="dt">form=</span> medv~., <span class="dt">data=</span>training,<span class="dt">method =</span><span class="st">&quot;ridge&quot;</span>)</code></pre></div>
<pre><code>## Loading required package: elasticnet</code></pre>
<pre><code>## Loading required package: lars</code></pre>
<pre><code>## Loaded lars 1.2</code></pre>
<pre><code>## Ridge Regression 
## 
## 381 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 381, 381, 381, 381, 381, 381, ... 
## Resampling results across tuning parameters:
## 
##   lambda  RMSE      Rsquared 
##   0e+00   5.069641  0.7107468
##   1e-04   5.069702  0.7107421
##   1e-01   5.158070  0.7042695
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was lambda = 0.</code></pre>
<p>This tells ut that the optimal value of lambda 0.</p>
</div>
<div id="section-4" class="section level2">
<h2>5</h2>
<p>Now, we are using 10 fold cross validation to find the best parameter lambda.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fitControl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">repeats =</span> <span class="dv">10</span>)
trainridgecv &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">form=</span> medv~., <span class="dt">data=</span>training,<span class="dt">method =</span><span class="st">&quot;ridge&quot;</span>,
                       <span class="dt">trControl =</span> fitControl)
trainridgecv</code></pre></div>
<pre><code>## Ridge Regression 
## 
## 381 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 344, 342, 343, 342, 342, 343, ... 
## Resampling results across tuning parameters:
## 
##   lambda  RMSE      Rsquared 
##   0e+00   4.800147  0.7412209
##   1e-04   4.800093  0.7412250
##   1e-01   4.834903  0.7383563
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was lambda = 1e-04.</code></pre>
<p>The ultimate value for lambda here is still 0.</p>
</div>
<div id="section-5" class="section level2">
<h2>6</h2>
<p>We test the models on our test data below</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testlm&lt;-<span class="kw">train</span>(<span class="dt">form=</span>medv~., <span class="dt">data=</span>testing, <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>)
testlm <span class="co">#RMSE 5,82 Rsq 0.621</span></code></pre></div>
<pre><code>## Linear Regression 
## 
## 125 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 125, 125, 125, 125, 125, 125, ... 
## Resampling results:
## 
##   RMSE      Rsquared 
##   5.192736  0.6724885
## 
## Tuning parameter 'intercept' was held constant at a value of TRUE
## </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testridge&lt;-<span class="kw">train</span>(<span class="dt">form=</span>medv~., <span class="dt">data=</span> testing, <span class="dt">method=</span><span class="st">&quot;ridge&quot;</span>, <span class="dt">lambda=</span><span class="dv">0</span>)
testridge <span class="co">#RMSE 5.49 Rsq 0.678</span></code></pre></div>
<pre><code>## Ridge Regression 
## 
## 125 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 125, 125, 125, 125, 125, 125, ... 
## Resampling results across tuning parameters:
## 
##   lambda  RMSE      Rsquared 
##   0e+00   5.485235  0.6453014
##   1e-04   5.484501  0.6453813
##   1e-01   5.263181  0.6737159
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was lambda = 0.1.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testridgecv &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">form=</span> medv~., <span class="dt">data=</span>testing,<span class="dt">method =</span><span class="st">&quot;ridge&quot;</span>,
                       <span class="dt">trControl =</span> fitControl, <span class="dt">lambda=</span><span class="dv">0</span>)
testridgecv <span class="co"># RMSE 5,13 Rsq 0.74</span></code></pre></div>
<pre><code>## Ridge Regression 
## 
## 125 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 113, 113, 113, 113, 112, 113, ... 
## Resampling results across tuning parameters:
## 
##   lambda  RMSE      Rsquared 
##   0e+00   4.830796  0.7386291
##   1e-04   4.830434  0.7386675
##   1e-01   4.751652  0.7502872
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was lambda = 0.1.</code></pre>
<p>The best model according to RMSE and Rsquared is the ridge method with lambda =0 and the 10 fold cross validation.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
